# 1. 是什么？
- docker不启动，默认网络情况

![image.png](https://cdn.nlark.com/yuque/0/2022/png/25452040/1644560106631-c6fa0508-d9f5-4707-989a-cdb0934a4c34.png#clientId=uf07285cf-cf20-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=720&id=u12017a6a&margin=%5Bobject%20Object%5D&name=image.png&originHeight=720&originWidth=1074&originalType=binary&ratio=1&rotation=0&showTitle=false&size=2324390&status=done&style=none&taskId=u9699eb29-fa31-46a3-981a-c540b4bcd25&title=&width=1074)
ens33
lo
virbr0
在CentOS7的安装过程中如果有选择相关虚拟化的的服务安装系统后，启动网卡时会发现有一个以网桥连接的私网地址的virbr0网卡(virbr0网卡：它还有一个固定的默认IP地址192.168.122.1)，是做虚拟机网桥的使用的，其作用是为连接其上的虚机网卡提供 NAT访问外网的功能。
Linux安装，勾选安装系统的时候附带了libvirt服务才会生成的一个东西，如果不需要可以直接将libvirtd服务卸载，
yum remove libvirt-libs.x86_64

- docker启动后，网络情况

会产生一个名为docker0的虚拟网桥
![image.png](https://cdn.nlark.com/yuque/0/2022/png/25452040/1644560278257-1bbadabe-cd88-4daf-b792-fa0d2ee876f8.png#clientId=uf07285cf-cf20-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=720&id=u89828888&margin=%5Bobject%20Object%5D&name=image.png&originHeight=720&originWidth=1152&originalType=binary&ratio=1&rotation=0&showTitle=false&size=2493135&status=done&style=none&taskId=u65263c88-d195-48cf-a958-b5efcda116b&title=&width=1152)

查看docker网络模式命令
当我们安装启动Docker后，会默认自动创建三个网络
```shell
[root@AliyunServer ~]# docker network ls
NETWORK ID     NAME      DRIVER    SCOPE
decbc8d10a7d   bridge    bridge    local
4e3ae86ce6c0   host      host      local
df31de48dbc2   none      null      local
```
# 2. 常用基本命令
## 2.1 所有命令
```shell
[root@AliyunServer ~]# docker network --help

Usage:  docker network COMMAND

Manage networks

Commands:
  connect     Connect a container to a network
  create      Create a network
  disconnect  Disconnect a container from a network
  inspect     Display detailed information on one or more networks
  ls          List networks
  prune       Remove all unused networks
  rm          Remove one or more networks
```
## 2.2 查看网络
docker network ls
## 2.3 查看网络源数据
docker network inspect  XXX网络名字
## 2.4 创建网络
docker network create  XXX网络名字
## 2.5 删除网络
docker network rm XXX网络名字
```shell
[root@AliyunServer ~]# docker network ls
NETWORK ID     NAME      DRIVER    SCOPE
decbc8d10a7d   bridge    bridge    local
4e3ae86ce6c0   host      host      local
df31de48dbc2   none      null      local
[root@AliyunServer ~]# docker network create mhk_network
0cdec720eeca373fbbec8e4d62d6170edf1ab0c5b70c0366df8926fd142477b0
[root@AliyunServer ~]# docker network ls
NETWORK ID     NAME          DRIVER    SCOPE
decbc8d10a7d   bridge        bridge    local
4e3ae86ce6c0   host          host      local
0cdec720eeca   mhk_network   bridge    local
df31de48dbc2   none          null      local
[root@AliyunServer ~]# docker network inspect mhk_network
[
    {
        "Name": "mhk_network",
        "Id": "0cdec720eeca373fbbec8e4d62d6170edf1ab0c5b70c0366df8926fd142477b0",
        "Created": "2022-02-11T14:25:58.492097368+08:00",
        "Scope": "local",
        "Driver": "bridge",
        "EnableIPv6": false,
        "IPAM": {
            "Driver": "default",
            "Options": {},
            "Config": [
                {
                    "Subnet": "172.18.0.0/16",
                    "Gateway": "172.18.0.1"
                }
            ]
        },
        "Internal": false,
        "Attachable": false,
        "Ingress": false,
        "ConfigFrom": {
            "Network": ""
        },
        "ConfigOnly": false,
        "Containers": {},
        "Options": {},
        "Labels": {}
    }
]
[root@AliyunServer ~]# docker network rm mhk_network
mhk_network
[root@AliyunServer ~]# docker network ls
NETWORK ID     NAME      DRIVER    SCOPE
decbc8d10a7d   bridge    bridge    local
4e3ae86ce6c0   host      host      local
df31de48dbc2   none      null      local
```
# 3. 能干嘛

- 容器间的互联和通信以及端口映射
- 容器IP变动时候可以通过服务名直接网络通信而不受到影响
# 4. 网络模式
## 4.1 总体介绍
| 网络模式 | 简介 |
| --- | --- |
| bridge | 为每一个容器分配、设置 IP 等，并将容器连接
到一个 docker0
虛拟网桥，默认为该模式 |
| host | 容器将不会虛拟出自己的网卡，配置自己的 IP
等，而是使用宿主机的 IP 和端口 |
| none | 容器有独立的 Network namespace, 但并没有
对其进行任何网络设置，如分配 veth pair 和网
桥连接，IP 等 |
| container | 新创建的容器不会创建自己的网卡和配置自己的
IP，而是和一个指定的容器共享IP、端口范围等 |

- bridge模式：使用--network  bridge指定，默认使用docker0
- host模式：使用--network host指定
- none模式：使用--network none指定
- container模式：使用--network container:NAME或者容器ID指定

## 4.2 容器实例内默认网络IP生产规则

1. 先启动两个ubuntu容器实例
```shell
[root@AliyunServer ~]# docker run -it --name u1 ubuntu bash
root@ace29a443ed1:/# [root@AliyunServer ~]#
[root@AliyunServer ~]# docker run -it --name u2 ubuntu bash
root@2b5e1241b9f6:/# [root@AliyunServer ~]#
[root@AliyunServer ~]# docker ps
CONTAINER ID   IMAGE                   COMMAND                  CREATED          STATUS          PORTS                                       NAMES
2b5e1241b9f6   ubuntu                  "bash"                   12 seconds ago   Up 11 seconds                                               u2
ace29a443ed1   ubuntu                  "bash"                   29 seconds ago   Up 28 seconds                                               u1
```

2. docker inspect 容器ID or 容器名字
```shell
[root@AliyunServer ~]# docker inspect u1 | tail -n 20
            "Networks": {
                "bridge": {
                    "IPAMConfig": null,
                    "Links": null,
                    "Aliases": null,
                    "NetworkID": "decbc8d10a7dc7d8bab5ebbc0e001f782308145b01ca11facb00b2748e23c9c1",
                    "EndpointID": "cac73ded1256ece0a3633cf8eca12d511961a1e5ec6158d44e08f4b639087474",
                    "Gateway": "172.17.0.1",
                    "IPAddress": "172.17.0.3",
                    "IPPrefixLen": 16,
                    "IPv6Gateway": "",
                    "GlobalIPv6Address": "",
                    "GlobalIPv6PrefixLen": 0,
                    "MacAddress": "02:42:ac:11:00:03",
                    "DriverOpts": null
                }
            }
        }
    }
]
[root@AliyunServer ~]# docker inspect u2 | tail -n 20
            "Networks": {
                "bridge": {
                    "IPAMConfig": null,
                    "Links": null,
                    "Aliases": null,
                    "NetworkID": "decbc8d10a7dc7d8bab5ebbc0e001f782308145b01ca11facb00b2748e23c9c1",
                    "EndpointID": "306ac2b34cdfac86902b1a451759dafc67da508348c5547114a30caf71a3e12c",
                    "Gateway": "172.17.0.1",
                    "IPAddress": "172.17.0.4",
                    "IPPrefixLen": 16,
                    "IPv6Gateway": "",
                    "GlobalIPv6Address": "",
                    "GlobalIPv6PrefixLen": 0,
                    "MacAddress": "02:42:ac:11:00:04",
                    "DriverOpts": null
                }
            }
        }
    }
]
```
u1: "IPAddress": "172.17.0.3"
u2: "IPAddress": "172.17.0.4"

3. 关闭u2实例，新建u3，查看ip变化
```shell
[root@AliyunServer ~]# docker stop u2
u2
[root@AliyunServer ~]# docker run -it --name u3 ubuntu bash
root@76d2db7c501e:/# [root@AliyunServer ~]#
[root@AliyunServer ~]# docker inspect u3 | tail -n 20
            "Networks": {
                "bridge": {
                    "IPAMConfig": null,
                    "Links": null,
                    "Aliases": null,
                    "NetworkID": "decbc8d10a7dc7d8bab5ebbc0e001f782308145b01ca11facb00b2748e23c9c1",
                    "EndpointID": "55eb1ba54b884ea4ad3cae50fc477de29d7fb080be808ef80a78c56b1871256f",
                    "Gateway": "172.17.0.1",
                    "IPAddress": "172.17.0.4",
                    "IPPrefixLen": 16,
                    "IPv6Gateway": "",
                    "GlobalIPv6Address": "",
                    "GlobalIPv6PrefixLen": 0,
                    "MacAddress": "02:42:ac:11:00:04",
                    "DriverOpts": null
                }
            }
        }
    }
]
```
u3: "IPAddress": "172.17.0.4"

**结论**
docker容器内部的ip是有可能会发生改变的

## 4.3 案例说明
### 4.3.1 bridge是什么
Docker 服务默认会创建一个 docker0 网桥（其上有一个 docker0 内部接口），该桥接网络的名称为docker0，它在内核层连通了其他的物理或虚拟网卡，这就将所有容器和本地主机都放到同一个物理网络。Docker 默认指定了 docker0 接口 的 IP 地址和子网掩码，让主机和容器之间可以通过网桥相互通信。

# 查看 bridge 网络的详细信息，并通过 grep 获取名称项
docker network inspect bridge | grep name
```shell
[root@AliyunServer ~]# docker network inspect bridge | grep name
            "com.docker.network.bridge.name": "docker0",
```
 ifconfig | grep docker
```shell
[root@AliyunServer ~]# ifconfig | grep docker
docker0: flags=4163<UP,BROADCAST,RUNNING,MULTICAST>  mtu 1500
```
案例说明:

1. Docker使用Linux桥接，在宿主机虚拟一个Docker容器网桥(docker0)，Docker启动一个容器时会根据Docker网桥的网段分配给容器一个IP地址，称为Container-IP，同时Docker网桥是每个容器的默认网关。因为在同一宿主机内的容器都接入同一个网桥，这样容器之间就能够通过容器的Container-IP直接通信。

 

2. docker run 的时候，没有指定network的话默认使用的网桥模式就是bridge，使用的就是docker0。在宿主机ifconfig,就可以看到docker0和自己create的network(后面讲)eth0，eth1，eth2……代表网卡一，网卡二，网卡三……，lo代表127.0.0.1，即localhost，inet addr用来表示网卡的IP地址

 

3. 网桥docker0创建一对对等虚拟设备接口一个叫veth，另一个叫eth0，成对匹配。

3.1 整个宿主机的网桥模式都是docker0，类似一个交换机有一堆接口，每个接口叫veth，在本地主机和容器内分别创建一个虚拟接口，并让他们彼此联通（这样一对接口叫veth pair）；
3.2 每个容器实例内部也有一块网卡，每个接口叫eth0；
3.3 docker0上面的每个veth匹配某个容器实例内部的eth0，两两配对，一一匹配。
通过上述，将宿主机上的所有容器都连接到这个内部网络上，两个容器在同一个网络下,会从这个网关下各自拿到分配的ip，此时两个容器的网络是互通的。
![image.png](https://cdn.nlark.com/yuque/0/2022/png/25452040/1644562582562-3bbef5f8-e8f9-4c7b-b660-066ed0f2d89b.png#clientId=uf07285cf-cf20-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=641&id=ue29b795b&margin=%5Bobject%20Object%5D&name=image.png&originHeight=641&originWidth=1280&originalType=binary&ratio=1&rotation=0&showTitle=false&size=2466140&status=done&style=none&taskId=uc7b1d955-aa73-4c73-b7cb-e1e2eeb8edd&title=&width=1280)

docker run -d -p 8081:8080   --name tomcat81 billygoo/tomcat8-jdk8
docker run -d -p 8082:8080   --name tomcat82 billygoo/tomcat8-jdk8
两两匹配验证
```shell
[root@AliyunServer ~]# docker run -d -p 8081:8080   --name tomcat81 billygoo/tomcat8-jdk8
b68c0b81895d7ab4738b99b70a2c1ca47827bcdb5dd5af4382234e317069a988
[root@AliyunServer ~]# docker run -d -p 8082:8080   --name tomcat82 billygoo/tomcat8-jdk8
7f295c92ca60944dd04f706217cc83f1cb9664f237009d8cd32cfe36d431f3b4

[root@AliyunServer ~]# ip addr | tail -n 8
60: veth1b481c2@if59: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc noqueue master docker0 state UP group default
    link/ether 2a:1b:4d:39:46:0c brd ff:ff:ff:ff:ff:ff link-netnsid 0
    inet6 fe80::281b:4dff:fe39:460c/64 scope link
       valid_lft forever preferred_lft forever
62: vethacb709e@if61: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc noqueue master docker0 state UP group default
    link/ether d6:eb:8c:61:7b:6f brd ff:ff:ff:ff:ff:ff link-netnsid 1
    inet6 fe80::d4eb:8cff:fe61:7b6f/64 scope link
       valid_lft forever preferred_lft forever

[root@AliyunServer ~]# docker exec -it tomcat81 bash
root@b68c0b81895d:/usr/local/tomcat# ip addr
1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000
    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
    inet 127.0.0.1/8 scope host lo
       valid_lft forever preferred_lft forever
59: eth0@if60: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc noqueue state UP group default
    link/ether 02:42:ac:11:00:02 brd ff:ff:ff:ff:ff:ff link-netnsid 0
    inet 172.17.0.2/16 brd 172.17.255.255 scope global eth0
       valid_lft forever preferred_lft forever
       
[root@AliyunServer ~]# docker exec -it tomcat82 bash
root@7f295c92ca60:/usr/local/tomcat# ip addr
1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000
    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
    inet 127.0.0.1/8 scope host lo
       valid_lft forever preferred_lft forever
61: eth0@if62: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc noqueue state UP group default
    link/ether 02:42:ac:11:00:03 brd ff:ff:ff:ff:ff:ff link-netnsid 0
    inet 172.17.0.3/16 brd 172.17.255.255 scope global eth0
       valid_lft forever preferred_lft forever
```
### 4.3.2 host是什么
直接使用宿主机的 IP 地址与外界进行通信，不再需要额外进行NAT 转换。
说明
容器将不会获得一个独立的Network Namespace， 而是和宿主机共用一个Network Namespace。容器将不会虚拟出自己的网卡而是使用宿主机的IP和端口。
![image.png](https://cdn.nlark.com/yuque/0/2022/png/25452040/1644563345277-5ec4462c-954e-4096-9910-2ab2c0f17595.png#clientId=uf07285cf-cf20-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=637&id=ubcfd6e43&margin=%5Bobject%20Object%5D&name=image.png&originHeight=637&originWidth=1280&originalType=binary&ratio=1&rotation=0&showTitle=false&size=2450747&status=done&style=none&taskId=ueb55ea0a-9a54-41e1-8de7-488c52937b3&title=&width=1280)
警告
docker run -d -p 8083:8080 --network host --name tomcat83 billygoo/tomcat8-jdk8
```shell
[root@AliyunServer ~]# docker run -d -p 8083:8080 --network host --name tomcat83 billygoo/tomcat8-jdk8
WARNING: Published ports are discarded when using host network mode
0fce992aaa7550ae9083cd30b59ef9ba70454559db8c4813da27c8ee4d6bbb66

[root@AliyunServer ~]# docker ps
CONTAINER ID   IMAGE                   COMMAND                  CREATED         STATUS         PORTS                                       NAMES
0fce992aaa75   billygoo/tomcat8-jdk8   "catalina.sh run"        8 seconds ago   Up 7 seconds                                               tomcat83
```
问题：
docke启动时总是遇见标题中的警告
原因：
docker启动时指定--network=host或-net=host，如果还指定了-p映射端口，那这个时候就会有此警告，
并且通过-p设置的参数将不会起到任何作用，端口号会以主机端口号为主，重复时则递增。
解决:
解决的办法就是使用docker的其他网络模式，例如--network=bridge，这样就可以解决问题，或者直接无视

正确
docker run -d                          --network host --name tomcat83 billygoo/tomcat8-jdk8
无之前的配对显示了，看容器实例内部
```shell
[root@AliyunServer ~]# docker run -d --network host --name tomcat83 billygoo/tomcat8-jdk8
4b61c552228b083388364c300006d46458b297b6f7ae528497d70f0465892d6c
[root@AliyunServer ~]# docker inspect tomcat83 | tail -n 20
            "Networks": {
                "host": {
                    "IPAMConfig": null,
                    "Links": null,
                    "Aliases": null,
                    "NetworkID": "4e3ae86ce6c0dd3326bb1b25cf664ac22fa7ba6e7b168d98d253efebdc758e3c",
                    "EndpointID": "d566a25620621f0ad5133e6d036014a6efc7acb232f1dc0b0560ed766b6721f6",
                    "Gateway": "",
                    "IPAddress": "",
                    "IPPrefixLen": 0,
                    "IPv6Gateway": "",
                    "GlobalIPv6Address": "",
                    "GlobalIPv6PrefixLen": 0,
                    "MacAddress": "",
                    "DriverOpts": null
                }
            }
        }
    }
]
```
没有设置-p的端口映射了，如何访问启动的tomcat83？？
http://宿主机IP:8080/
在CentOS里面用默认的火狐浏览器访问容器内的tomcat83看到访问成功，因为此时容器的IP借用主机的，
所以容器共享宿主机网络IP，这样的好处是外部主机与容器可以直接通信。

### 4.3.3 none是什么
在none模式下，并不为Docker容器进行任何网络配置。 
也就是说，这个Docker容器没有网卡、IP、路由等信息，只有一个lo
需要我们自己为Docker容器添加网卡、配置IP等。

禁用网络功能，只有lo标识(就是127.0.0.1表示本地回环)

案例
docker run -d -p 8084:8080 --network none --name tomcat84 billygoo/tomcat8-jdk8
进入容器内部查看
```shell
[root@AliyunServer ~]# docker run -d -p 8084:8080 --network none --name tomcat84 billygoo/tomcat8-jdk8
fa1b6de1a2fc596551eb057f60a45eeab1857991eb5b553c1ce645661a6cee4f
[root@AliyunServer ~]# docker exec -it tomcat84 bash
root@fa1b6de1a2fc:/usr/local/tomcat# ip addr
1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000
    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
    inet 127.0.0.1/8 scope host lo
       valid_lft forever preferred_lft forever
```
在容器外部查看
```shell
[root@AliyunServer ~]# docker inspect tomcat84 | tail -n 20
            "Networks": {
                "none": {
                    "IPAMConfig": null,
                    "Links": null,
                    "Aliases": null,
                    "NetworkID": "df31de48dbc2a88b5c806505ee6a05deec807cdfde97b7ff48d532c37691b9cd",
                    "EndpointID": "3388e4e94ad031e7f9886ae66a7d13d3decf840df47ee37eac23b558885ce8f2",
                    "Gateway": "",
                    "IPAddress": "",
                    "IPPrefixLen": 0,
                    "IPv6Gateway": "",
                    "GlobalIPv6Address": "",
                    "GlobalIPv6PrefixLen": 0,
                    "MacAddress": "",
                    "DriverOpts": null
                }
            }
        }
    }
]
```
### 4.3.4 container是什么
container⽹络模式 
新建的容器和已经存在的一个容器共享一个网络ip配置而不是和宿主机共享。新创建的容器不会创建自己的网卡，配置自己的IP，而是和一个指定的容器共享IP、端口范围等。同样，两个容器除了网络方面，其他的如文件系统、进程列表等还是隔离的。
![image.png](https://cdn.nlark.com/yuque/0/2022/png/25452040/1644564013436-1da4f7cb-3928-4b17-a6b7-f1564170fa12.png#clientId=uf07285cf-cf20-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=679&id=u83aa62f4&margin=%5Bobject%20Object%5D&name=image.png&originHeight=679&originWidth=1280&originalType=binary&ratio=1&rotation=0&showTitle=false&size=2612334&status=done&style=none&taskId=uc94a6bb9-1530-4057-9b41-9d93ca44313&title=&width=1280)

案例1:
docker run -d -p 8085:8080                                     --name tomcat85 billygoo/tomcat8-jdk8
docker run -d -p 8086:8080 --network container:tomcat85 --name tomcat86 billygoo/tomcat8-jdk8

运行结果
```shell
[root@AliyunServer ~]# docker run -d -p 8085:8080 --name tomcat85 billygoo/tomcat8-jdk8
8ba2c478fd5a0af08ae219a3bb1477d58cbca11d8f72fe9a59869bc07e00ad7b
[root@AliyunServer ~]# docker run -d -p 8086:8080 --network container:tomcat85 --name tomcat86 billygoo/tomcat8-jdk8
docker: Error response from daemon: conflicting options: port publishing and the container type network mode.
See 'docker run --help'.
```
# 相当于tomcat86和tomcat85公用同一个ip同一个端口，导致端口冲突

案例2:
Alpine Linux 是一款独立的、非商业的通用 Linux 发行版，专为追求安全性、简单性和资源效率的用户而设计。 可能很多人没听说过这个 Linux 发行版本，但是经常用 Docker 的朋友可能都用过，因为他小，简单，安全而著称，所以作为基础镜像是非常好的一个选择，可谓是麻雀虽小但五脏俱全，镜像非常小巧，不到 6M的大小，所以特别适合容器打包。

docker run -it                                                    --name alpine1  alpine /bin/sh
docker run -it --network container:alpine1 --name alpine2  alpine /bin/sh
```shell
[root@AliyunServer ~]# docker run -it  --name alpine1  alpine /bin/sh
Unable to find image 'alpine:latest' locally
latest: Pulling from library/alpine
59bf1c3509f3: Pull complete
Digest: sha256:21a3deaa0d32a8057914f36584b5288d2e5ecc984380bc0118285c70fa8c9300
Status: Downloaded newer image for alpine:latest
/ # ip addr
1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue state UNKNOWN qlen 1000
    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
    inet 127.0.0.1/8 scope host lo
       valid_lft forever preferred_lft forever
65: eth0@if66: <BROADCAST,MULTICAST,UP,LOWER_UP,M-DOWN> mtu 1500 qdisc noqueue state UP
    link/ether 02:42:ac:11:00:05 brd ff:ff:ff:ff:ff:ff
    inet 172.17.0.5/16 brd 172.17.255.255 scope global eth0
       valid_lft forever preferred_lft forever

[root@AliyunServer ~]# docker run -it --network container:alpine1 --name alpine2  alpine /bin/sh
/ # ip addr
1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue state UNKNOWN qlen 1000
    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
    inet 127.0.0.1/8 scope host lo
       valid_lft forever preferred_lft forever
65: eth0@if66: <BROADCAST,MULTICAST,UP,LOWER_UP,M-DOWN> mtu 1500 qdisc noqueue state UP
    link/ether 02:42:ac:11:00:05 brd ff:ff:ff:ff:ff:ff
    inet 172.17.0.5/16 brd 172.17.255.255 scope global eth0
       valid_lft forever preferred_lft forever
/ #
```
假如此时关闭alpine1，再看看alpine2
```shell
[root@AliyunServer ~]# docker stop alpine1
alpine1
[root@AliyunServer ~]# docker exec -it alpine2 /bin/sh
/ # ip addr
1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue state UNKNOWN qlen 1000
    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
    inet 127.0.0.1/8 scope host lo
       valid_lft forever preferred_lft forever
/ #
```
### 4.3.5 自定义网络
过时的link
![image.png](https://cdn.nlark.com/yuque/0/2022/png/25452040/1644564530388-58dc3338-c0f6-4437-891b-3a1183039d61.png#clientId=uf07285cf-cf20-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=720&id=u27bd99a7&margin=%5Bobject%20Object%5D&name=image.png&originHeight=720&originWidth=1165&originalType=binary&ratio=1&rotation=0&showTitle=false&size=2521268&status=done&style=none&taskId=u39a7e470-5ad5-481a-af16-31213698a8e&title=&width=1165)

**是什么**
before
案例
docker run -d -p 8081:8080   --name tomcat81 billygoo/tomcat8-jdk8
docker run -d -p 8082:8080   --name tomcat82 billygoo/tomcat8-jdk8
上述成功启动并用docker exec进入各自容器实例内部
问题
按照IP地址ping是OK的
![image.png](https://cdn.nlark.com/yuque/0/2022/png/25452040/1644564656709-e95edf73-3202-4220-89f6-15f3ee88cd5b.png#clientId=uf07285cf-cf20-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=365&id=u3339cab8&margin=%5Bobject%20Object%5D&name=image.png&originHeight=365&originWidth=1280&originalType=binary&ratio=1&rotation=0&showTitle=false&size=1404311&status=done&style=none&taskId=u9d3c4969-6b61-44ea-bc88-fb986079eb4&title=&width=1280)
![image.png](https://cdn.nlark.com/yuque/0/2022/png/25452040/1644564664552-81248fef-da52-49cf-9dd2-f8eb73b46504.png#clientId=uf07285cf-cf20-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=349&id=ub40bafe4&margin=%5Bobject%20Object%5D&name=image.png&originHeight=349&originWidth=1280&originalType=binary&ratio=1&rotation=0&showTitle=false&size=1342749&status=done&style=none&taskId=u4da3d665-439a-4187-a368-d2920240d00&title=&width=1280)

按照服务名ping结果报错
![image.png](https://cdn.nlark.com/yuque/0/2022/png/25452040/1644564747403-07816628-1978-41b4-8c16-1cb1dbec5495.png#clientId=uf07285cf-cf20-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=212&id=ueca19887&margin=%5Bobject%20Object%5D&name=image.png&originHeight=212&originWidth=1280&originalType=binary&ratio=1&rotation=0&showTitle=false&size=815684&status=done&style=none&taskId=u25d922b0-1652-4daf-9e51-eee5f725f0c&title=&width=1280)
![image.png](https://cdn.nlark.com/yuque/0/2022/png/25452040/1644564754177-8de1256f-e391-4d0b-b543-7e185515c17c.png#clientId=uf07285cf-cf20-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=210&id=uf841cca5&margin=%5Bobject%20Object%5D&name=image.png&originHeight=210&originWidth=1280&originalType=binary&ratio=1&rotation=0&showTitle=false&size=807990&status=done&style=none&taskId=u101cee34-1376-47a4-8360-8036348b085&title=&width=1280)

after
案例
自定义桥接网络,自定义网络默认使用的是桥接网络bridge
新建自定义网络
```shell
[root@AliyunServer ~]# docker network create mhk_network
568eb7f19c1e1c631d1626ec28075a338f4e20724c1615ba5c979018f07e8968
[root@AliyunServer ~]# docker network ls
NETWORK ID     NAME          DRIVER    SCOPE
decbc8d10a7d   bridge        bridge    local
4e3ae86ce6c0   host          host      local
568eb7f19c1e   mhk_network   bridge    local
df31de48dbc2   none          null      local
[root@AliyunServer ~]#
```
新建容器加入上一步新建的自定义网络
docker run -d -p 8081:8080 --network mhk_network  --name tomcat81 billygoo/tomcat8-jdk8
docker run -d -p 8082:8080 --network mhk_network  --name tomcat82 billygoo/tomcat8-jdk8
```shell
[root@AliyunServer ~]# docker run -d -p 8081:8080 --network mhk_network  --name tomcat81 billygoo/tomcat8-jdk8
8f01b278f16dd8394330c58a13fe203b2a0f71ad6a924b9eff8c7c453c5284b1
[root@AliyunServer ~]# docker run -d -p 8082:8080 --network mhk_network  --name tomcat82 billygoo/tomcat8-jdk8
bae2fa7ace167625e0a602c4ed1e27a081d1647a008f7b2588aba0e9fa6d0cf4
[root@AliyunServer ~]# docker exec -it tomcat81 bash
root@8f01b278f16d:/usr/local/tomcat# ping tomcat82
PING tomcat82 (172.19.0.3) 56(84) bytes of data.
64 bytes from tomcat82.mhk_network (172.19.0.3): icmp_seq=1 ttl=64 time=0.092 ms
64 bytes from tomcat82.mhk_network (172.19.0.3): icmp_seq=2 ttl=64 time=0.102 ms
64 bytes from tomcat82.mhk_network (172.19.0.3): icmp_seq=3 ttl=64 time=0.081 ms
^C
--- tomcat82 ping statistics ---
3 packets transmitted, 3 received, 0% packet loss, time 1999ms
rtt min/avg/max/mdev = 0.081/0.091/0.102/0.014 ms
root@8f01b278f16d:/usr/local/tomcat# read escape sequence
[root@AliyunServer ~]# docker exec -it tomcat82 bash
root@bae2fa7ace16:/usr/local/tomcat# ping tomcat81
PING tomcat81 (172.19.0.2) 56(84) bytes of data.
64 bytes from tomcat81.mhk_network (172.19.0.2): icmp_seq=1 ttl=64 time=0.055 ms
64 bytes from tomcat81.mhk_network (172.19.0.2): icmp_seq=2 ttl=64 time=0.096 ms
64 bytes from tomcat81.mhk_network (172.19.0.2): icmp_seq=3 ttl=64 time=0.074 ms
64 bytes from tomcat81.mhk_network (172.19.0.2): icmp_seq=4 ttl=64 time=0.093 ms
^C
--- tomcat81 ping statistics ---
4 packets transmitted, 4 received, 0% packet loss, time 2999ms
rtt min/avg/max/mdev = 0.055/0.079/0.096/0.018 ms
```
问题结论
自定义网络本身就维护好了主机名和ip的对应关系（ip和域名都能通）

# 5. Docker平台架构图解
## 5.1 整体说明
从其架构和运行流程来看，Docker 是一个 C/S 模式的架构，后端是一个松耦合架构，众多模块各司其职。 

Docker 运行的基本流程为：

1. 用户是使用 Docker Client 与 Docker Daemon 建立通信，并发送请求给后者。
1. Docker Daemon 作为 Docker 架构中的主体部分，首先提供 Docker Server 的功能使其可以接受 Docker Client 的请求。
1. Docker Engine 执行 Docker 内部的一系列工作，每一项工作都是以一个 Job 的形式的存在。
1. Job 的运行过程中，当需要容器镜像时，则从 Docker Registry 中下载镜像，并通过镜像管理驱动 Graph driver将下载镜像以Graph的形式存储。
1. 当需要为 Docker 创建网络环境时，通过网络管理驱动 Network driver 创建并配置 Docker 容器网络环境。
1. 当需要限制 Docker 容器运行资源或执行用户指令等操作时，则通过 Execdriver 来完成。
1. Libcontainer是一项独立的容器管理包，Network driver以及Exec driver都是通过Libcontainer来实现具体对容器进行的操作。

## 5.2 整体架构
![image.png](https://cdn.nlark.com/yuque/0/2022/png/25452040/1644565302502-ec9ec176-7179-4e6a-9d84-8c7e0a916864.png#clientId=uf07285cf-cf20-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=1001&id=u39be24ac&margin=%5Bobject%20Object%5D&name=image.png&originHeight=1001&originWidth=720&originalType=binary&ratio=1&rotation=0&showTitle=false&size=2166743&status=done&style=none&taskId=u66e92c4a-918b-4735-aadb-d58d43d667b&title=&width=720)
